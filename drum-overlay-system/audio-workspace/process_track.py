import sys
import json
from pathlib import Path
import numpy as np
import librosa
import soundfile as sf
import torch as th
from demucs.pretrained import get_model_from_args, ModelLoadingError
from demucs.apply import apply_model
from demucs.audio import convert_audio, save_audio, AudioFile
import torchaudio as ta
import subprocess


def print_header():
    print("=" * 60)
    print("AUDIO PROCESSING PIPELINE")
    print("=" * 60)


def print_footer():
    print("=" * 60)
    print("✓ PROCESSING COMPLETE")
    print("=" * 60)


def load_track(track, audio_channels, samplerate):
    errors = {}
    wav = None

    try:
        wav = AudioFile(track).read(
            streams=0,
            samplerate=samplerate,
            channels=audio_channels)
    except FileNotFoundError:
        errors['ffmpeg'] = 'FFmpeg is not installed.'
    except subprocess.CalledProcessError:
        errors['ffmpeg'] = 'FFmpeg could not read the file.'

    if wav is None:
        try:
            wav, sr = ta.load(str(track))
        except RuntimeError as err:
            errors['torchaudio'] = err.args[0]
        else:
            wav = convert_audio(wav, sr, samplerate, audio_channels)

    if wav is None:
        print(f"Could not load file {track}. "
              "Maybe it is not a supported file format? ")
        for backend, error in errors.items():
            print(f"When trying to load using {backend}, got the following error: {error}")
        sys.exit(1)
    return wav


def separate_stems(audio_path: Path, model="htdemucs_6s"):
    """
    Separates the audio file into stems using the Demucs Python API.
    Saves them as WAV files in the current directory.
    """
    print("[1/4] Initializing Demucs separator...")
    
    # Create dummy args for model loading
    class Args:
        name = model
        repo = None
        device = "cuda" if th.cuda.is_available() else "cpu"
        shifts = 1
        overlap = 0.25
        split = True
        segment = None
        jobs = 0
        
    try:
        model = get_model_from_args(Args())
    except ModelLoadingError as e:
        print(f"❌ Failed to initialize Demucs separator: {e}")
        print("   Please ensure you have a working internet connection for the first run to download models.")
        raise
    except Exception as e:
        print(f"❌ Failed to initialize Demucs separator: {e}")
        raise

    model.cpu()
    model.eval()

    print("[2/4] Separating stems (this can take 30-90 seconds)...")
    try:
        wav = load_track(audio_path, model.audio_channels, model.samplerate)
        
        ref = wav.mean(0)
        wav -= ref.mean()
        wav /= ref.std()
        
        sources = apply_model(model, wav[None], device=Args().device, 
                           shifts=Args().shifts, split=Args().split, 
                           overlap=Args().overlap, progress=True,
                           num_workers=Args().jobs, segment=Args().segment)[0]
        
        sources *= ref.std()
        sources += ref.mean()

    except Exception as e:
        print(f"❌ Demucs separation failed: {e}")
        raise

    print("[3/4] Saving separated stems...")
    saved_stems = []
    for source, stem_name in zip(sources, model.sources):
        stem_path = Path(f"{stem_name}.wav")
        save_audio(source, str(stem_path), samplerate=model.samplerate, 
                  bits_per_sample=16, clip="rescale")
        print(f"      ✓ Saved {stem_path.name}")
        saved_stems.append(stem_path)

    drum_stem_path = Path("drums.wav")
    if not drum_stem_path.exists():
        raise FileNotFoundError("drums.wav was not generated by Demucs.")

    return drum_stem_path, model.samplerate


def analyze_drum_hits(drum_track_path: Path, sample_rate: int):
    """
    Analyzes the drum track for kick, snare, and hat onsets using Librosa,
    based on the frequency bands from TECHNICAL_SPECS.md.
    """
    print("[4/4] Analyzing drum hits...")

    try:
        y, sr = librosa.load(drum_track_path, sr=sample_rate)
    except Exception as e:
        print(f"❌ Failed to load drum track: {e}")
        raise

    stft = librosa.stft(y, hop_length=512)
    stft_mag = np.abs(stft)

    # Configuration from TECHNICAL_SPECS.md
    hit_config = {
        "kick": {"fmin": 40, "fmax": 150, "delta": 0.05, "wait": 10},
        "snare": {"fmin": 150, "fmax": 6000, "delta": 0.03, "wait": 8},
        "hats": {"fmin": 6000, "fmax": 16000, "delta": 0.02, "wait": 5},
    }

    all_hits = {}
    all_velocities = {drum_type: [] for drum_type in hit_config}

    for drum_type, params in hit_config.items():
        freq_range = librosa.fft_frequencies(sr=sr)
        freq_bins = (freq_range >= params["fmin"]) & (freq_range <= params["fmax"])

        # Spectral flux in the frequency band
        onset_env = librosa.onset.onset_strength(S=stft_mag[freq_bins, :], sr=sr)
        onset_frames = librosa.onset.onset_detect(
            onset_envelope=onset_env,
            sr=sr,
            hop_length=512,
            units="frames",
            delta=params["delta"],
            wait=params["wait"],
        )

        # Calculate velocity based on energy at onset
        hit_data = []
        if len(onset_frames) > 0:
            onset_times = librosa.frames_to_time(onset_frames, sr=sr, hop_length=512)
            for i, frame in enumerate(onset_frames):
                energy = np.sum(stft_mag[freq_bins, frame] ** 2)
                velocity = np.sqrt(energy)
                all_velocities[drum_type].append(velocity)
                hit_data.append([onset_times[i], velocity])

        all_hits[drum_type] = hit_data

    # Normalize velocities for each drum type
    for drum_type, hits in all_hits.items():
        max_velocity = np.max(all_velocities[drum_type]) if all_velocities[drum_type] else 1.0
        if max_velocity > 0:
            for hit in hits:
                hit[1] /= max_velocity # Normalize to 0-1 range
        print(f"      ✓ {drum_type.capitalize()}: {len(hits)} hits detected")

    return all_hits


def main():
    """
    Main orchestration function.
    """
    if len(sys.argv) < 2:
        print("❌ ERROR: Please provide the path to an audio file.")
        print(f"   Usage: python {sys.argv[0]} your_track.wav")
        sys.exit(1)

    track_path = Path(sys.argv[1]).resolve()
    if not track_path.exists():
        print(f"❌ ERROR: Input audio file not found at '{track_path}'")
        sys.exit(1)

    print_header()

    try:
        # 1. Separate audio into stems
        drum_stem_path, sample_rate = separate_stems(track_path)

        # 2. Analyze drum hits from the drum stem
        trigger_data = analyze_drum_hits(drum_stem_path, sample_rate)

        # 3. Save trigger data to JSON
        output_json_path = Path("drum-data.json")
        with open(output_json_path, "w") as f:
            json.dump(trigger_data, f, indent=2)
        print(f"\n✓ Successfully saved trigger data to {output_json_path}")

    except Exception as e:
        print(f"\nERROR: Audio processing failed. Reason: {e}")
        sys.exit(1)

    print_footer()


if __name__ == "__main__":
    main()